{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db3ee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Comparing Tree Growth Strategies\n",
      "==================================================\n",
      "ðŸš€ Training with Level-wise trees (batch_size=1\n",
      "   Objective: reg:squarederror, Loss: mse, Base score: -0.0095\n",
      "   NODE layers disabled.\n",
      "   GOSS: top_rate=0.2, other_rate=0.1\n",
      "   DART: rate_drop=0.1, skip_drop=0.5, normalize_type=tree, one_drop=no\n",
      "   Binning: binned (hist), 256 bins\n",
      "   Training on 4000 samples with 10 features\n",
      "[  10] Train: 0.565381, Val: 0.652812, Time: 0.23s\n",
      "[  20] Train: 0.130102, Val: 0.175642, Time: 0.38s\n",
      "[  30] Train: 0.040024, Val: 0.067765, Time: 0.48s\n",
      "[  40] Train: 0.027387, Val: 0.049963, Time: 0.55s\n",
      "[  50] Train: 0.023890, Val: 0.044788, Time: 0.62s\n",
      "âœ… Training completed in 0.62s, 50 trees\n",
      "   Time: 0.62s\n",
      "   Test MSE: 0.044788\n",
      "   Trees: 50\n",
      "   Feature Importances: [3.55186823e-01 3.24687004e-01 3.18762310e-01 1.21449909e-04\n",
      " 2.07482414e-04 3.63795373e-04 9.07822997e-05 2.41901777e-04\n",
      " 1.82462106e-04 1.55989074e-04]\n"
     ]
    }
   ],
   "source": [
    "from boosting import BoostRegressor\n",
    "import numpy as np\n",
    "import time\n",
    "# ================ USAGE EXAMPLE ================\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    n_samples, n_features = 5000, 10\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    y = np.sum(X[:, :3], axis=1) + 0.1 * np.random.randn(n_samples)\n",
    "    \n",
    "    # Split data\n",
    "    split_idx = int(0.8 * n_samples)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    print(\"ðŸ”¥ Comparing Tree Growth Strategies\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Level-wise (original)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_level = BoostRegressor(\n",
    "        n_estimators=50,\n",
    "        learning_rate=0.1,\n",
    "        adaptive_lr=False,\n",
    "        lr_schedule=\"cosine_restart\",  # Original approach\n",
    "        max_depth=6,\n",
    "        tree_learner=\"level\",  # Original approach\n",
    "        tree_method=\"binned\",\n",
    "        binned_mode=\"hist\",\n",
    "        verbose=True,\n",
    "        batch_size=1,\n",
    "        use_gpu=False,\n",
    "        use_goss=True,\n",
    "        use_neural=False,  # Original approach\n",
    "        enable_interactions=False,\n",
    "    )\n",
    "\n",
    "    \n",
    "    model_level.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "    level_time = time.time() - start_time\n",
    "    level_pred = model_level.predict(X_test)\n",
    "    level_mse = np.mean((y_test - level_pred) ** 2)\n",
    "    print(f\"   Time: {level_time:.2f}s\")\n",
    "    print(f\"   Test MSE: {level_mse:.6f}\")\n",
    "    print(f\"   Trees: {len(model_level.trees)}\")\n",
    "    \n",
    "    # print feature importances\n",
    "    importances = model_level.feature_importances()\n",
    "    print(\"   Feature Importances:\", importances)\n",
    "    # # plot feature importances like shap\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # plt.bar(range(n_features), importances)\n",
    "    # plt.xlabel(\"Feature\")\n",
    "    # plt.ylabel(\"Importance\")\n",
    "    # plt.title(\"Feature Importances\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # # # # compare with scikit learn's GradientBoostingRegressor\n",
    "    # from sklearn.ensemble import GradientBoostingRegressor\n",
    "    # model_sklearn = GradientBoostingRegressor(\n",
    "    #     n_estimators=50,\n",
    "    #     learning_rate=0.1,\n",
    "    #     max_depth=6,\n",
    "    #     verbose=1,\n",
    "    #     random_state=4\n",
    "    # )\n",
    "    # model_sklearn.fit(X_train, y_train)\n",
    "    # sklearn_time = time.time() - start_time\n",
    "    # sklearn_pred = model_sklearn.predict(X_test)\n",
    "    # sklearn_mse = np.mean((y_test - sklearn_pred) ** 2)\n",
    "    # print(f\"   Scikit-learn Time: {sklearn_time:.2f}s\")\n",
    "    # print(f\"   Scikit-learn Test MSE: {sklearn_mse:.6f}\")\n",
    "    # print(f\"   Scikit-learn Trees: {len(model_sklearn.estimators_)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa06419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PIQP Multistage Solver\n",
      "========================================\n",
      "Problem size: 28 variables, 15 equality, 56 inequality constraints\n",
      "Detected multistage structure: 3 stages\n",
      "\n",
      "Structure detection: Enabled\n",
      "Detected structure: {'detected': True, 'num_stages': 3, 'block_sizes': [7, 7, 7], 'arrow_size': 7, 'total_vars': 28}\n",
      "Iter 0: r_prim=0.00e+00, r_eq=8.46e-01, r_ineq=4.00e+00, r_comp=9.90e-01, Î¼=1.00e-01\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linalg.solve_triangular: The input tensor B must have at least 2 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 849\u001b[39m\n\u001b[32m    844\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Speedup:    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeedup\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx, Obj diff: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_diff\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    848\u001b[39m     \u001b[38;5;66;03m# Run tests\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m     test_result = \u001b[43mtest_piqp_multistage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    850\u001b[39m     benchmark_against_dense()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 766\u001b[39m, in \u001b[36mtest_piqp_multistage\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    763\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDetected structure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver.structure_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    765\u001b[39m \u001b[38;5;66;03m# Solve\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m result = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResults:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    769\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 587\u001b[39m, in \u001b[36mPiqpMultistageSolver.solve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    586\u001b[39m \u001b[38;5;66;03m# Compute Newton step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m steps = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresiduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# Compute step size\u001b[39;00m\n\u001b[32m    590\u001b[39m alpha = \u001b[38;5;28mself\u001b[39m._compute_step_size(steps)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 465\u001b[39m, in \u001b[36mPiqpMultistageSolver._compute_step\u001b[39m\u001b[34m(self, residuals)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_structure:\n\u001b[32m    464\u001b[39m     \u001b[38;5;28mself\u001b[39m._setup_structured_matrix(Psi)\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     dx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbtda_matrix\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# Standard dense solve\u001b[39;00m\n\u001b[32m    468\u001b[39m     dx = torch.linalg.solve(Psi, rhs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 150\u001b[39m, in \u001b[36mBlockTriDiagArrowMatrix.solve\u001b[39m\u001b[34m(self, rhs)\u001b[39m\n\u001b[32m    147\u001b[39m x_blocks = []\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Step 1: Î”x^k_0 = L_{0,0}^{-1} rÌ„^k_0\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m x0 = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve_triangular\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mL_diagonal\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m x_blocks.append(x0)\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Steps 2-4: Main forward loop\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: linalg.solve_triangular: The input tensor B must have at least 2 dimensions."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539a0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceecab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training with Leaf-wise trees (batch_size=1\n",
      "   Objective: reg:squarederror, Loss: mse, Base score: -0.0095\n",
      "   NODE layers disabled.\n",
      "   GOSS: top_rate=0.2, other_rate=0.1\n",
      "   DART: rate_drop=0.1, skip_drop=0.5, normalize_type=tree, one_drop=no\n",
      "   Binning: hist (hist), 256 bins\n",
      "   Training on 4000 samples with 10 features\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tree_method must be 'binned' or 'exact'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      3\u001b[39m BoostRegressor = add_shap_to_boostregressor(BoostRegressor)\n\u001b[32m      5\u001b[39m model_level = BoostRegressor(\n\u001b[32m      6\u001b[39m     n_estimators=\u001b[32m50\u001b[39m,\n\u001b[32m      7\u001b[39m     learning_rate=\u001b[32m0.1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     batch_size=\u001b[32m1\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mmodel_level\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m level_time = time.time() - start_time\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Set background for proper expected value\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/baseline/foreblocks/foretools/foretree/boosting.py:843\u001b[39m, in \u001b[36mBoostRegressor.fit\u001b[39m\u001b[34m(self, X, y, eval_set, verbose)\u001b[39m\n\u001b[32m    840\u001b[39m grad, hess = \u001b[38;5;28mself\u001b[39m.loss_fn.grad_hess(y, y_pred_iter)\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# 3) Build a batch of trees from (X, grad, hess)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m trees = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;66;03m# 4) LR for this round; store per-tree LRs\u001b[39;00m\n\u001b[32m    846\u001b[39m current_lr = \u001b[38;5;28mself\u001b[39m._get_learning_rate(iteration)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/baseline/foreblocks/foretools/foretree/boosting.py:712\u001b[39m, in \u001b[36mBoostRegressor._build_tree_batch\u001b[39m\u001b[34m(self, X, y, grad, hess)\u001b[39m\n\u001b[32m    710\u001b[39m n_features_tree = \u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.sampling_config.colsample_bytree * n_features))\n\u001b[32m    711\u001b[39m feature_mask = \u001b[38;5;28mself\u001b[39m._rng.choice(n_features, size=n_features_tree, replace=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m tree = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[38;5;66;03m# ---------------- Build histograms (FAST) or fallback (DENSE) ----------------\u001b[39;00m\n\u001b[32m    715\u001b[39m tree._histogram_system = \u001b[38;5;28mself\u001b[39m._histogram_system.clone(feature_idx=feature_mask, row_idx=selected_idx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/baseline/foreblocks/foretools/foretree/boosting.py:550\u001b[39m, in \u001b[36mBoostRegressor._create_tree\u001b[39m\u001b[34m(self, feature_mask)\u001b[39m\n\u001b[32m    529\u001b[39m common_args = {\n\u001b[32m    530\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.tree_config.max_depth,\n\u001b[32m    531\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmin_samples_split\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.tree_config.min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33menable_interactions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.enable_interactions,\n\u001b[32m    548\u001b[39m }\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tree_learner == \u001b[33m\"\u001b[39m\u001b[33mleaf\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnifiedTree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_leaves\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_leaves\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcommon_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrowth_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleaf_wise\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m UnifiedTree(\n\u001b[32m    557\u001b[39m         max_leaves=\u001b[38;5;28mself\u001b[39m.tree_config.max_leaves,\n\u001b[32m    558\u001b[39m         **common_args,\n\u001b[32m    559\u001b[39m         growth_policy=\u001b[33m\"\u001b[39m\u001b[33mlevel_wise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    560\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/baseline/foreblocks/foretools/foretree/boosting_tree.py:65\u001b[39m, in \u001b[36mUnifiedTree.__init__\u001b[39m\u001b[34m(self, growth_policy, max_depth, max_leaves, min_samples_split, min_samples_leaf, min_child_weight, lambda_, gamma, alpha, max_delta_step, tree_method, binned_mode, n_bins, feature_indices, bin_edges, monotone_constraints, interaction_constraints, gpu_accelerator, n_jobs, adaptive_hist, use_gpu, feature_importance_, enable_interactions)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgrowth_policy must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mleaf_wise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel_wise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tree_method \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mbinned\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mexact\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtree_method must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinned\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexact\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tree_method == \u001b[33m\"\u001b[39m\u001b[33mbinned\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m binned_mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapprox\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madaptive\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     70\u001b[39m ):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mbinned_mode must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mapprox\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, or \u001b[39m\u001b[33m'\u001b[39m\u001b[33madaptive\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: tree_method must be 'binned' or 'exact'"
     ]
    }
   ],
   "source": [
    "from shap import *\n",
    "\n",
    "BoostRegressor = add_shap_to_boostregressor(BoostRegressor)\n",
    "\n",
    "model_level = BoostRegressor(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    tree_learner=\"leaf\",  # Original approach\n",
    "    tree_method=\"hist\",\n",
    "    verbose=True,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "model_level.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "level_time = time.time() - start_time\n",
    "# Set background for proper expected value\n",
    "model_level.set_shap_background(X_train[:100])  # Use sample of training data\n",
    "\n",
    "# Compute SHAP values (should have much lower additivity errors)\n",
    "shap_values = model_level.shap_values(X_test[:10], debug=True)\n",
    "\n",
    "# Validate the fix\n",
    "# Explain individual predictions\n",
    "explanation = model_level.explain_prediction(X_test[0])\n",
    "# Get feature importance\n",
    "#importance = model_level.shap_feature_importance(X_test[:100])\n",
    "#print(\"Feature Importance:\", importance)\n",
    "\n",
    "# Analyze model behavior\n",
    "#shap_values = model_level.shap_values(X_test[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SHAP to your model\n",
    "from your_corrected_shap import add_shap_to_boostregressor\n",
    "\n",
    "add_shap_to_boostregressor(BoostRegressor)\n",
    "\n",
    "# Train model\n",
    "model = BoostRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
